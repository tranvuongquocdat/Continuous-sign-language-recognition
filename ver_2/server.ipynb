{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "import struct\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import load_model\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "from pydub import AudioSegment\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Hàm để vẽ và lấy keypoints\n",
    "def draw_keypoints(image, keypoints, keypoint_ids):\n",
    "    tmp_lst = []\n",
    "    for idx, keypoint in enumerate(keypoints):\n",
    "        if idx in keypoint_ids:\n",
    "            x = int(keypoint.x * image.shape[1])\n",
    "            y = int(keypoint.y * image.shape[0])\n",
    "            tmp_lst.append(x)\n",
    "            tmp_lst.append(y)\n",
    "    return tmp_lst\n",
    "\n",
    "def visualize(res):\n",
    "    global frame1\n",
    "    # Convert the data to percentages\n",
    "    percentages = np.array(res).flatten() * 100\n",
    "\n",
    "    # Colors for the bars: blue if >90% else purple\n",
    "    colors = [(0, 255, 0) if value > 90 else (128, 0, 128) for value in percentages]\n",
    "\n",
    "    # Create a white frame\n",
    "    frame1 = np.ones((480, 720, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Dimensions for the bar chart\n",
    "    bar_height = 30\n",
    "    spacing = 15\n",
    "    max_width = 650  # max width for the bars\n",
    "    left_margin = 50  # left margin position\n",
    "    num_bars = len(res[0])  # number of bars\n",
    "\n",
    "    # Generate random names for demonstration\n",
    "    names = ['Goi dien', 'Sua', 'Dat nuoc', 'Doi bung', 'Ten',  'Gao', 'Chap nhan', 'Cam on', 'Giup do', 'Tim kiem']\n",
    "\n",
    "    # Draw each horizontal bar, name, and the segmented 100% mark\n",
    "    for i, (percentage, name) in enumerate(zip(percentages, names)):\n",
    "        # Calculate the width and position of each bar\n",
    "        bar_width = int((percentage / 100) * max_width)\n",
    "        y_position = i * (bar_height + spacing) + 50\n",
    "\n",
    "        # Draw the bar\n",
    "        cv2.rectangle(frame1, \n",
    "                      (left_margin, y_position), \n",
    "                      (left_margin + bar_width, y_position + bar_height), \n",
    "                      colors[i], \n",
    "                      -1)\n",
    "\n",
    "        # Add horizontal name on the bar\n",
    "        text_position = (left_margin + 5, y_position + bar_height - 10)\n",
    "        cv2.putText(frame1, name, text_position, cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.4, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Draw the segmented 100% mark\n",
    "    segment_height = int(420 / num_bars)  # height of each segment\n",
    "    for i in range(num_bars):\n",
    "        segment_y_position = 50 + i * (segment_height + spacing)\n",
    "        cv2.line(frame1, (left_margin + max_width, segment_y_position), \n",
    "                 (left_margin + max_width, segment_y_position + segment_height), (0, 0, 0), 1)\n",
    "\n",
    "    cv2.putText(frame1, '100%', (left_margin + max_width - 30, 40), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.4, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Add x and y axis labels\n",
    "    cv2.putText(frame1, 'Percentage (%)', (600, 20), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame1, 'ID', (10, 470), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return frame1\n",
    "\n",
    "def detect_and_visualize(model, sequence, result_queue):\n",
    "    global res \n",
    "    res = model.predict(sequence, verbose=0)\n",
    "    result_queue.put(res)\n",
    "\n",
    "def play_audio(audio_id):\n",
    "    id_to_filename = {\n",
    "                        0: '017.mp3',\n",
    "                        1: '021.mp3',\n",
    "                        2: '026.mp3',\n",
    "                        3: '033.mp3',\n",
    "                        4: '039.mp3',\n",
    "                        5: '044.mp3',\n",
    "                        6: '050.mp3',\n",
    "                        7: '051.mp3',\n",
    "                        8: '056.mp3',\n",
    "                        9: '064.mp3'\n",
    "                    }\n",
    "    \n",
    "    folder_path = 'Voices'\n",
    "    \n",
    "    if audio_id in id_to_filename:\n",
    "        audio_file_name = id_to_filename[audio_id]\n",
    "        audio_file_path = os.path.join(folder_path, audio_file_name)\n",
    "        \n",
    "        if os.path.isfile(audio_file_path):\n",
    "            playsound(audio_file_path)\n",
    "        else:\n",
    "            print(f\"The file {audio_file_name} does not exist.\")\n",
    "    else:\n",
    "        print(\"Invalid ID. Please enter an ID between 0 and 9.\")\n",
    "\n",
    "# Set mediapipe model \n",
    "def process_webcam_stream(model):\n",
    "    #initial value\n",
    "    max_length = 120\n",
    "    keypoint_ids = [15, 17, 19, 21, 16, 18, 20, 22, 0, 2, 5]\n",
    "    # khởi tạo socket\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind(('0.0.0.0', 123))\n",
    "    server_socket.listen(10)\n",
    "    conn, addr = server_socket.accept()\n",
    "    print(f\"Đã kết nối với client tại địa chỉ: {addr}\")\n",
    "    #khởi tạo nhận data\n",
    "    data = b\"\"\n",
    "    payload_size = struct.calcsize(\"L\")\n",
    "\n",
    "    # Khởi tạo MediaPipe Pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    pose = mp_pose.Pose()\n",
    "    #khoi tao queue\n",
    "    result_queue = queue.Queue()\n",
    "    # 1. New detection variables\n",
    "    predictions = {key: 0 for key in range(10)}\n",
    "    sequence = []\n",
    "    threshold = 0.985\n",
    "    step_count = 0\n",
    "    max_step_count = 10      #khoảng cách giữa 2 lần detect\n",
    "    fps_count = 0\n",
    "    time_count = 0\n",
    "    frame1 = np.ones((480, 720, 3), dtype=np.uint8) * 255\n",
    "    send_prediction = 404    #biến tin nhắn mặc định được gửi đi\n",
    "    send_count = 0   #biến đềm thời gian giữa 2 lần gửi tin nhắn\n",
    "    delay_detect_frame = 0\n",
    "\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        while len(data) < payload_size:\n",
    "            data += conn.recv(4096)\n",
    "\n",
    "        packed_msg_size = data[:payload_size]\n",
    "        data = data[payload_size:]\n",
    "        msg_size = struct.unpack(\"L\", packed_msg_size)[0]\n",
    "\n",
    "        while len(data) < msg_size:\n",
    "            data += conn.recv(4096)\n",
    "\n",
    "        frame_data = data[:msg_size]\n",
    "        data = data[msg_size:]\n",
    "        frame = np.frombuffer(frame_data, dtype=np.uint8)\n",
    "        frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)\n",
    "        # Xoay frame 90 độ về bên trái\n",
    "        frame = cv2.transpose(frame)\n",
    "        frame = cv2.flip(frame, 0)\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame, (960, 1080))\n",
    "\n",
    "        # Xử lý frame để trích xuất keypoints\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mpDraw.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            keypoints = draw_keypoints(frame, results.pose_landmarks.landmark, keypoint_ids)\n",
    "            sequence.append(keypoints)\n",
    "            step_count += 1\n",
    "            if len(sequence) >= max_length and step_count > max_step_count and delay_detect_frame == 0:   \n",
    "                sequence = [sequence[-max_length:]]   \n",
    "                # predict\n",
    "                t1 = threading.Thread(target = detect_and_visualize, args = (model, [sequence], result_queue))\n",
    "                t1.start()  \n",
    "\n",
    "                if not result_queue.empty():\n",
    "                    res = result_queue.get()\n",
    "                    # print(res)\n",
    "                    # t2 = threading.Thread(target = visualize, args = (res))\n",
    "                    # t2.start()\n",
    "                    if res[0][np.argmax(res)] > threshold:\n",
    "                        predictions[np.argmax(res)] += 1\n",
    "                        if predictions[np.argmax(res)] == 3:\n",
    "                            print(np.argmax(res))\n",
    "                            send_prediction = np.argmax(res)\n",
    "                            delay_detect_frame = 60\n",
    "                            predictions = {key: 0 for key in predictions}\n",
    "                            t2 = threading.Thread(target = play_audio, args = (int(np.argmax(res)),))\n",
    "                            t2.start()\n",
    "                    frame1 = visualize(res)\n",
    "\n",
    "                step_count = 0\n",
    "\n",
    "        if delay_detect_frame > 0:\n",
    "            delay_detect_frame -= 1\n",
    "        else:\n",
    "            send_prediction = 404\n",
    "\n",
    "        if send_count == 10:\n",
    "            result = str(send_prediction).zfill(3).encode()\n",
    "            conn.sendall(result)\n",
    "            send_count = 0\n",
    "        else:\n",
    "            send_count += 1\n",
    "        \n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', frame)\n",
    "        cv2.imshow(\"Visualization\", frame1)\n",
    "\n",
    "        #calculate FPS\n",
    "        time_count += time.time() - start\n",
    "        if fps_count == 30:\n",
    "            print(f\"FPS: {1/(time_count/ 30):.2f}\")\n",
    "            time_count = 0\n",
    "            fps_count = 0\n",
    "        fps_count += 1\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã kết nối với client tại địa chỉ: ('192.168.1.4', 54460)\n",
      "FPS: 21.13\n",
      "FPS: 28.76\n",
      "FPS: 28.63\n",
      "FPS: 28.36\n",
      "FPS: 30.21\n",
      "FPS: 29.36\n",
      "FPS: 29.47\n",
      "FPS: 29.64\n",
      "FPS: 29.13\n",
      "FPS: 30.33\n",
      "FPS: 29.38\n",
      "FPS: 28.74\n",
      "FPS: 29.24\n",
      "FPS: 28.79\n",
      "FPS: 29.94\n",
      "FPS: 28.65\n",
      "FPS: 30.00\n",
      "FPS: 29.53\n",
      "FPS: 30.00\n",
      "FPS: 28.93\n",
      "FPS: 30.18\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\yolo_data\\sign language new\\data_new_approach\\server.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmodel_checkpoint_4.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Gọi hàm xử lý video từ webcam\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m process_webcam_stream(model)\n",
      "\u001b[1;32md:\\yolo_data\\sign language new\\data_new_approach\\server.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=238'>239</a>\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m10\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=239'>240</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=240'>241</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/yolo_data/sign%20language%20new/data_new_approach/server.ipynb#W1sZmlsZQ%3D%3D?line=241'>242</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = load_model(r\"model\\model_checkpoint_4.h5\")\n",
    "\n",
    "# Gọi hàm xử lý video từ webcam\n",
    "process_webcam_stream(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
